2024-04-02 18:57:29,245 - INFO] DVC training
2024-04-02 18:57:29,245 - INFO] config :
2024-04-02 18:57:29,247 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 1024,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}
dataset find image:  323060
epoch 0
Train epoch 0: [0/80765 (0.0%)]	Loss: 399.347 |	MSE loss: 0.384 |	Bpp loss: 6.25 |	Aux loss: 0.00
/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode)
/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:4004: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  "Default grid_sample and affine_grid behavior has changed "
Train epoch 0: [2000/80765 (1.2%)]	Loss: 1.872 |	MSE loss: 0.001 |	Bpp loss: 0.54 |	Aux loss: 0.00
Train Epoch : 00 [1000/80765 (  1%)] Avgloss:7.229163 lr:0.0001 time:0.14588483516483516
details : warppsnr : 22.99 interpsnr : 22.82 psnr : 24.21
bpp :0.745497, bpp_mv :0.357514, bpp_res :0.238561
Train epoch 0: [4000/80765 (2.5%)]	Loss: 3.738 |	MSE loss: 0.003 |	Bpp loss: 0.81 |	Aux loss: 0.00
Train Epoch : 00 [2000/80765 (  2%)] Avgloss:3.336937 lr:0.0001 time:0.14488088400000002
details : warppsnr : 23.99 interpsnr : 24.21 psnr : 27.84
bpp :0.587270, bpp_mv :0.227532, bpp_res :0.245409
Traceback (most recent call last):
  File "main_dvc.py", line 395, in <module>
    global_step = train(epoch, global_step)
  File "main_dvc.py", line 232, in train
    optimizer.step()
  File "/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py", line 88, in wrapper
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 28, in decorate_context
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py", line 144, in step
    eps=group['eps'])
  File "/opt/conda/lib/python3.7/site-packages/torch/optim/_functional.py", line 98, in adam
    param.addcdiv_(exp_avg, denom, value=-step_size)
KeyboardInterrupt